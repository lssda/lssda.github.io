---
layout: page
---

<h1 class="h1-display text-center">Productive, Performant Software for Large Scale Scientific Data Analysis</h1>

<div class="mx-5 my-5 p-4 text-center text-white rounded-3" style="background: rgb(var(--bs-primary-rgb));">
  <p class="lead">October 21&ndash;22, 2025</p>
  <p class="lead">Redwood Rooms</p>
  <p class="lead mb-0">SLAC National Accelerator Laboratory</p>
</div>

# Overview

Scientific user facilities (SUFs) at the U.S. Department of Energy (DOE) drive scientific discovery and innovation by delivering world-class experimental capabilities that expand the frontiers of biology, chemistry, physics, and materials science. Over the next 5 years, upgrades at SUFs will generate over an order of magnitude more data, promising to accelerate the pace of scientific innovation if correctly harnessed. However, this flood of data poses challenges for the scientific community. The current state of the practice and tools optimized for HPC are insufficiently flexible and productive to address the high-stakes, short timelines, and rapidly evolving requirements of highly dynamic scientific user experiments. Additionally, traditional HPC software tools require deep computing expertise that scientific users may not be able to provide.

This workshop will explore the research challenges and opportunities in building a highly productive, high-performance software ecosystem for large scale scientific data analysis for users at the SUFs. The goal of the workshop is to identify key research directions that, if addressed, would substantially improve the productivity of the SUF user community and deliver an order of magnitude increase in productivity across the DOE complex.

# Organizing Committee

 * Alex Aiken (Stanford/SLAC)
 * Elliott Slaughter (SLAC)
 * Johannes Blaschke (NERSC)
 * Keita Teranishi (ORNL)
 * Patrick McCormick (LANL)
 * Roberto Gioiosa (PNNL)
